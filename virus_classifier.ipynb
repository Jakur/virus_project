{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = r\"C:/Code/bioinfo/data/fullset_test.csv\"\n",
    "df = pd.read_csv(f, names=[\"name\", \"seq\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'A': 0, 'T': 1, 'C': 2, 'G': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_fn(string):\n",
    "    x = [mapping[x] for x in string]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\"seq\"].apply(lambda x: mapping_fn(x))\n",
    "data2 = np.zeros((len(df), 300), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(data):\n",
    "    data2[i, :] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26405, 300)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensor_output = torch.tensor(df['class'].values, dtype=torch.float)\n",
    "torch_tensor_vectors = torch.from_numpy(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor_vectors.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26405, 300])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_VEC_SIZE = 32\n",
    "DNA_BASES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Example, self).__init__()\n",
    "        self.embed = nn.Embedding(DNA_BASES, EMBEDDING_VEC_SIZE)\n",
    "        self.fc = nn.Linear(300 * 32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = x.flatten()\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.751\n",
      "[1,  4000] loss: 0.826\n",
      "[1,  6000] loss: 0.990\n",
      "[1,  8000] loss: 1.048\n",
      "[1, 10000] loss: 1.079\n",
      "[1, 12000] loss: 1.094\n",
      "[1, 14000] loss: 1.151\n",
      "[1, 16000] loss: 1.168\n",
      "[1, 18000] loss: 1.123\n",
      "[1, 20000] loss: 1.098\n",
      "[1, 22000] loss: 1.084\n",
      "[1, 24000] loss: 1.094\n",
      "[1, 26000] loss: 1.096\n",
      "[2,  2000] loss: 0.780\n",
      "[2,  4000] loss: 0.834\n",
      "[2,  6000] loss: 0.938\n",
      "[2,  8000] loss: 1.018\n",
      "[2, 10000] loss: 1.050\n",
      "[2, 12000] loss: 1.067\n",
      "[2, 14000] loss: 1.132\n",
      "[2, 16000] loss: 1.136\n",
      "[2, 18000] loss: 1.107\n",
      "[2, 20000] loss: 1.079\n",
      "[2, 22000] loss: 1.062\n",
      "[2, 24000] loss: 1.061\n",
      "[2, 26000] loss: 1.045\n",
      "[3,  2000] loss: 0.824\n",
      "[3,  4000] loss: 0.812\n",
      "[3,  6000] loss: 0.899\n",
      "[3,  8000] loss: 0.970\n",
      "[3, 10000] loss: 1.000\n",
      "[3, 12000] loss: 1.032\n",
      "[3, 14000] loss: 1.093\n",
      "[3, 16000] loss: 1.090\n",
      "[3, 18000] loss: 1.063\n",
      "[3, 20000] loss: 1.041\n",
      "[3, 22000] loss: 1.021\n",
      "[3, 24000] loss: 1.028\n",
      "[3, 26000] loss: 1.041\n",
      "[4,  2000] loss: 0.791\n",
      "[4,  4000] loss: 0.825\n",
      "[4,  6000] loss: 0.932\n",
      "[4,  8000] loss: 1.017\n",
      "[4, 10000] loss: 1.034\n",
      "[4, 12000] loss: 1.047\n",
      "[4, 14000] loss: 1.110\n",
      "[4, 16000] loss: 1.115\n",
      "[4, 18000] loss: 1.080\n",
      "[4, 20000] loss: 1.053\n",
      "[4, 22000] loss: 1.036\n",
      "[4, 24000] loss: 1.043\n",
      "[4, 26000] loss: 1.053\n",
      "[5,  2000] loss: 0.743\n",
      "[5,  4000] loss: 0.746\n",
      "[5,  6000] loss: 0.870\n",
      "[5,  8000] loss: 0.976\n",
      "[5, 10000] loss: 1.009\n",
      "[5, 12000] loss: 1.033\n",
      "[5, 14000] loss: 1.090\n",
      "[5, 16000] loss: 1.076\n",
      "[5, 18000] loss: 1.048\n",
      "[5, 20000] loss: 1.022\n",
      "[5, 22000] loss: 1.019\n",
      "[5, 24000] loss: 1.026\n",
      "[5, 26000] loss: 1.035\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(zip(torch_tensor_vectors, torch_tensor_output)):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        epoch_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, epoch_loss / (i + 1)))\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
