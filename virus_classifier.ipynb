{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.7.0)\nRequirement already satisfied: future in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torch) (0.18.2)\nRequirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torch) (3.7.4.3)\nRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torch) (1.19.2)\nRequirement already satisfied: dataclasses in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torch) (0.6)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.1 is available.\nYou should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.1.4)\nRequirement already satisfied: python-dateutil>=2.7.3 in /Users/ksing121/Library/Python/3.7/lib/python/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (2020.4)\nRequirement already satisfied: numpy>=1.15.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas) (1.19.2)\nRequirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.1 is available.\nYou should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = r\"data/fullset_test.csv\"\n",
    "df = pd.read_csv(f, names=[\"name\", \"seq\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'A': 0, 'T': 1, 'C': 2, 'G': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_fn(string):\n",
    "    x = [mapping[x] for x in string]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\"seq\"].apply(lambda x: mapping_fn(x))\n",
    "data2 = np.zeros((len(df), 300), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(data):\n",
    "    data2[i, :] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(26405, 300)"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_tensor_output = torch.tensor(df['class'].values, dtype=torch.float)\n",
    "torch_tensor_vectors = torch.from_numpy(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.int64"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "torch_tensor_vectors.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([26405, 300])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "torch_tensor_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_VEC_SIZE = 32\n",
    "DNA_BASES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Example, self).__init__()\n",
    "        self.embed = nn.Embedding(DNA_BASES, EMBEDDING_VEC_SIZE)\n",
    "        self.fc = nn.Linear(300 * 32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = x.flatten()\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1,  2000] loss: 1.007\n[1,  4000] loss: 0.852\n[1,  6000] loss: 0.931\n[1,  8000] loss: 0.950\n[1, 10000] loss: 0.966\n[1, 12000] loss: 1.018\n[1, 14000] loss: 1.134\n[1, 16000] loss: 1.171\n[1, 18000] loss: 1.164\n[1, 20000] loss: 1.166\n[1, 22000] loss: 1.160\n[1, 24000] loss: 1.180\n[1, 26000] loss: 1.191\n[2,  2000] loss: 1.041\n[2,  4000] loss: 0.917\n[2,  6000] loss: 0.983\n[2,  8000] loss: 0.981\n[2, 10000] loss: 1.086\n[2, 12000] loss: 1.103\n[2, 14000] loss: 1.171\n[2, 16000] loss: 1.171\n[2, 18000] loss: 1.155\n[2, 20000] loss: 1.151\n[2, 22000] loss: 1.162\n[2, 24000] loss: 1.186\n[2, 26000] loss: 1.210\n[3,  2000] loss: 1.195\n[3,  4000] loss: 1.148\n[3,  6000] loss: 1.203\n[3,  8000] loss: 1.301\n[3, 10000] loss: 1.332\n[3, 12000] loss: 1.352\n[3, 14000] loss: 1.421\n[3, 16000] loss: 1.449\n[3, 18000] loss: 1.419\n[3, 20000] loss: 1.408\n[3, 22000] loss: 1.416\n[3, 24000] loss: 1.449\n[3, 26000] loss: 1.477\n[4,  2000] loss: 1.265\n[4,  4000] loss: 1.247\n[4,  6000] loss: 1.358\n[4,  8000] loss: 1.409\n[4, 10000] loss: 1.457\n[4, 12000] loss: 1.476\n[4, 14000] loss: 1.544\n[4, 16000] loss: 1.548\n[4, 18000] loss: 1.518\n[4, 20000] loss: 1.510\n[4, 22000] loss: 1.501\n[4, 24000] loss: 1.510\n[4, 26000] loss: 1.530\n[5,  2000] loss: 1.344\n[5,  4000] loss: 1.309\n[5,  6000] loss: 1.373\n[5,  8000] loss: 1.429\n[5, 10000] loss: 1.515\n[5, 12000] loss: 1.533\n[5, 14000] loss: 1.577\n[5, 16000] loss: 1.588\n[5, 18000] loss: 1.561\n[5, 20000] loss: 1.548\n[5, 22000] loss: 1.543\n[5, 24000] loss: 1.554\n[5, 26000] loss: 1.560\nFinished Training\n"
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(zip(torch_tensor_vectors, torch_tensor_output)):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = labels.view(1)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        epoch_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, epoch_loss / (i + 1)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class seqData(Dataset):   \n",
    "    def __init__(self, sequences, labels):\n",
    "        self.data = torch.from_numpy(sequences)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)   \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        data_val = self.data[index]\n",
    "        return data_val,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = seqData(data2, df['class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([1, 3, 0, 3, 2, 0, 2, 0, 1, 0, 1, 2, 1, 3, 1, 3, 3, 3, 3, 2, 0, 3, 3, 1,\n         3, 3, 3, 3, 0, 0, 1, 0, 0, 0, 2, 0, 3, 2, 0, 2, 0, 0, 1, 1, 0, 2, 0, 1,\n         0, 3, 2, 1, 0, 3, 1, 0, 1, 1, 1, 1, 3, 2, 2, 1, 1, 1, 1, 1, 2, 0, 1, 1,\n         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 0, 2, 2, 1, 2, 0, 1, 0, 1,\n         1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 3, 1, 0, 0, 3, 1, 1, 3, 3, 2, 1,\n         1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 3, 2, 0, 0, 1, 0, 1, 0, 0, 0,\n         0, 2, 0, 0, 0, 0, 0, 0, 1, 3, 2, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 3,\n         2, 0, 0, 1, 3, 3, 1, 1, 1, 1, 2, 0, 0, 3, 0, 1, 3, 1, 3, 3, 1, 2, 1, 2,\n         0, 0, 0, 3, 1, 3, 1, 3, 0, 1, 1, 1, 2, 2, 0, 3, 3, 3, 3, 1, 1, 2, 2, 2,\n         0, 0, 3, 0, 2, 2, 2, 1, 1, 2, 0, 3, 0, 1, 2, 1, 3, 2, 0, 0, 3, 3, 1, 2,\n         0, 0, 1, 1, 1, 3, 1, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 1, 3, 0, 1, 3, 1, 1,\n         0, 2, 2, 1, 2, 3, 1, 3, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1,\n         1, 2, 0, 2, 0, 0, 3, 2, 0, 0, 2, 2]),\n tensor(0.))"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "train_dataset.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAT_SIZE = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=BAT_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1,  2000] loss: 1.865\n[1,  4000] loss: 1.774\n[1,  6000] loss: 1.619\n[1,  8000] loss: 1.604\n[1, 10000] loss: 1.604\n[1, 12000] loss: 1.654\n[1, 14000] loss: 1.617\n[1, 16000] loss: 1.598\n[1, 18000] loss: 1.549\n[1, 20000] loss: 1.540\n[1, 22000] loss: 1.531\n[1, 24000] loss: 1.518\n[1, 26000] loss: 1.533\n[2,  2000] loss: 1.627\n[2,  4000] loss: 1.627\n[2,  6000] loss: 1.662\n[2,  8000] loss: 1.638\n[2, 10000] loss: 1.756\n[2, 12000] loss: 1.732\n[2, 14000] loss: 1.707\n[2, 16000] loss: 1.699\n[2, 18000] loss: 1.700\n[2, 20000] loss: 1.684\n[2, 22000] loss: 1.668\n[2, 24000] loss: 1.613\n[2, 26000] loss: 1.583\n[3,  2000] loss: 1.335\n[3,  4000] loss: 1.507\n[3,  6000] loss: 1.532\n[3,  8000] loss: 1.585\n[3, 10000] loss: 1.615\n[3, 12000] loss: 1.543\n[3, 14000] loss: 1.537\n[3, 16000] loss: 1.606\n[3, 18000] loss: 1.619\n[3, 20000] loss: 1.601\n[3, 22000] loss: 1.629\n[3, 24000] loss: 1.619\n[3, 26000] loss: 1.609\n[4,  2000] loss: 1.445\n[4,  4000] loss: 1.448\n[4,  6000] loss: 1.476\n[4,  8000] loss: 1.595\n[4, 10000] loss: 1.563\n[4, 12000] loss: 1.642\n[4, 14000] loss: 1.661\n[4, 16000] loss: 1.614\n[4, 18000] loss: 1.613\n[4, 20000] loss: 1.630\n[4, 22000] loss: 1.612\n[4, 24000] loss: 1.604\n[4, 26000] loss: 1.607\n[5,  2000] loss: 1.480\n[5,  4000] loss: 1.530\n[5,  6000] loss: 1.611\n[5,  8000] loss: 1.615\n[5, 10000] loss: 1.660\n[5, 12000] loss: 1.616\n[5, 14000] loss: 1.681\n[5, 16000] loss: 1.651\n[5, 18000] loss: 1.665\n[5, 20000] loss: 1.634\n[5, 22000] loss: 1.605\n[5, 24000] loss: 1.649\n[5, 26000] loss: 1.608\nFinished Training\n"
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #labels = labels.view(1)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        epoch_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, epoch_loss / (i + 1)))\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1607319086246"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}